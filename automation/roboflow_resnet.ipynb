{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet of roboflow\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/captcha-challenger/hcaptcha-model-factory/blob/main/automation/roboflow_resnet.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wF7rJGAOEMEU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "is_executing": true,
    "id": "x9-KvKZREMEW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporting the configuration from [`zip_dataset.py`](https://github.com/CaptchaAgent/hcaptcha-model-factory/blob/main/automation/zip_dataset.py)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = \"\"\n",
    "task_name = \"robot\"\n",
    "onnx_archive_name = \"robot2312\"\n",
    "\n",
    "# If you are training a nested model,\n",
    "# you need to specify the `solver.handle(prompt)` it is bound to.\n",
    "# Otherwise, please set it to empty\n",
    "NESTED_PROMPT = \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## No need to change the code below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Injecting Mystical Power into AutoDL\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "IS_AUTODL_PLATFORM = None\n",
    "if Path(\"/root/autodl-pub\").exists() and Path(\"/root/autodl-tmp\").exists():\n",
    "    IS_AUTODL_PLATFORM = True\n",
    "    result = subprocess.run(\n",
    "        'bash -c \"source /etc/network_turbo && env | grep proxy\"',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "    output = result.stdout\n",
    "    for line in output.splitlines():\n",
    "        if \"=\" in line:\n",
    "            var, value = line.split(\"=\", 1)\n",
    "            os.environ[var] = value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install loguru onnx fire hcaptcha-challenger\n",
    "!git clone https://github.com/CaptchaAgent/hcaptcha-model-factory.git\n",
    "!mv -f hcaptcha-model-factory/src src\n",
    "!rm -rf hcaptcha-model-factory/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hcaptcha_challenger as solver\n",
    "\n",
    "os.environ[\"GITHUB_TOKEN\"] = GITHUB_TOKEN\n",
    "onnx_archive_name = onnx_archive_name.replace(\".onnx\", \"\")\n",
    "\n",
    "solver.diagnose_task(task_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upload zip type datasets to `[PROJECT_DIR]/`"
   ],
   "metadata": {
    "collapsed": false,
    "id": "FsDuWg0wEMEZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import zipfile\n",
    "\n",
    "this_dir = Path(os.path.abspath(\".\"))\n",
    "project_dir = this_dir\n",
    "\n",
    "model_dir = project_dir.joinpath(\"model\")\n",
    "factory_data_dir = project_dir.joinpath(\"data\")\n",
    "source_dir = project_dir.joinpath(\"src\")\n",
    "zip_path = project_dir.joinpath(f\"{task_name}.zip\")\n",
    "\n",
    "if not zip_path.exists():\n",
    "    raise FileNotFoundError\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    z.extractall(factory_data_dir.joinpath(task_name))"
   ],
   "metadata": {
    "id": "y9au1FLBdCxb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "IBEbJ7yWEMEZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd {source_dir}\n",
    "\n",
    "from factories.resnet import ResNet\n",
    "\n",
    "# - INPUT: `[PROJECT]/data/<task_name>`\n",
    "# - OUTPUT: `[PROJECT]/model/<task_name>/<task_name.onnx>`\n",
    "\n",
    "model = ResNet(\n",
    "    task_name=task_name,\n",
    "    epochs=None,  # default to 200\n",
    "    batch_size=None,  # default to 4\n",
    "    dir_dataset=str(factory_data_dir),\n",
    "    dir_model=str(model_dir),\n",
    ")\n",
    "model.train()\n",
    "model.conv_pth2onnx(verbose=False)"
   ],
   "metadata": {
    "id": "n6qqwsJ_EMEa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Deploy model to GitHub"
   ],
   "metadata": {
    "collapsed": false,
    "id": "skqVHm_uEMEa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.getpreferredencoding = lambda d=True: \"UTF-8\"\n",
    "\n",
    "!pip install PyGithub\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "from github import Auth, Github, GithubException\n",
    "\n",
    "\n",
    "def quick_development():\n",
    "    auth = Auth.Token(os.getenv(\"GITHUB_TOKEN\"))\n",
    "    repo = Github(auth=auth).get_repo(\"QIN2DIM/hcaptcha-challenger\")\n",
    "    modelhub_title = \"ONNX ModelHub\"\n",
    "\n",
    "    model_path = model_dir.joinpath(task_name, f\"{task_name}.onnx\")\n",
    "    pending_onnx_path = model_dir.joinpath(task_name, f\"{onnx_archive_name}.onnx\")\n",
    "    shutil.copy(model_path, pending_onnx_path)\n",
    "\n",
    "    for release in repo.get_releases():\n",
    "        if release.title != modelhub_title:\n",
    "            continue\n",
    "        try:\n",
    "            asset = release.upload_asset(path=str(pending_onnx_path))\n",
    "        except GithubException as err:\n",
    "            if err.status == 422:\n",
    "                logger.error(\n",
    "                    f\"The model file already exists, please manually replace the file with the same name - url={repo.releases_url}\",\n",
    "                    url=repo.releases_url,\n",
    "                )\n",
    "        except Exception as err:\n",
    "            logger.error(err)\n",
    "        else:\n",
    "            logger.success(\n",
    "                f\"Model file uploaded successfully \"\n",
    "                f\"- name={asset.name} url={asset.browser_download_url}\"\n",
    "            )\n",
    "            return asset.id\n",
    "\n",
    "\n",
    "if not os.getenv(\"GITHUB_TOKEN\"):\n",
    "    logger.warning(\"Skip model deployment, miss GITHUB TOKEN\")\n",
    "    sys.exit()\n",
    "\n",
    "aid = quick_development()\n",
    "aid"
   ],
   "metadata": {
    "id": "WiVpLjU5EMEa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rolling upgrade"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import yaml\n",
    "from github.GitReleaseAsset import GitReleaseAsset\n",
    "from github.Repository import Repository\n",
    "from hcaptcha_challenger import ModelHub, handle\n",
    "import hcaptcha_challenger as solver\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Objects:\n",
    "    branches: Dict[str, Any]\n",
    "    circle_seg: str\n",
    "    clip_candidates: Dict[str, List[str]]\n",
    "    nested_categories: Dict[str, List[str]]\n",
    "    ashes_of_war: Dict[str, Any]\n",
    "    label_alias: Dict[str, Any]\n",
    "    datalake: dict\n",
    "\n",
    "    @classmethod\n",
    "    def from_modelhub(cls, modelhub: ModelHub):\n",
    "        data = yaml.safe_load(modelhub.objects_path.read_text(encoding=\"utf8\"))\n",
    "        return cls(\n",
    "            **{\n",
    "                key: (data[key] if val.default == val.empty else data.get(key, val.default))\n",
    "                for key, val in inspect.signature(cls).parameters.items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def to_yaml(self, path: Path = None):\n",
    "        path = path or Path(\"objects-tmp.yaml\")\n",
    "        with open(path, \"w\", encoding=\"utf8\") as file:\n",
    "            yaml.safe_dump(self.__dict__, file, sort_keys=False, allow_unicode=True)\n",
    "        return path\n",
    "\n",
    "    @staticmethod\n",
    "    def to_asset(repo: Repository, data_tmp_path: Path, message: str = \"\"):\n",
    "        content = data_tmp_path.read_bytes()\n",
    "        message = message or f\"Automated deployment @ utc {datetime.utcnow()}\"\n",
    "        remote_path = \"src/objects.yaml\"\n",
    "        sha = repo.get_contents(path=remote_path).sha\n",
    "        return repo.update_file(\n",
    "            branch=\"main\", path=remote_path, message=message, content=content, sha=sha\n",
    "        )\n",
    "\n",
    "\n",
    "class Annotator:\n",
    "    auth = Auth.Token(os.getenv(\"GITHUB_TOKEN\"))\n",
    "    repo = Github(auth=auth).get_repo(\"QIN2DIM/hcaptcha-challenger\")\n",
    "\n",
    "    def __init__(self, asset_id: int, matched_label: str = \"\"):\n",
    "        self._asset_id = asset_id\n",
    "        self._matched_label = matched_label\n",
    "\n",
    "        self._asset: GitReleaseAsset | None = None\n",
    "\n",
    "        solver.install(upgrade=True)\n",
    "\n",
    "        self.modelhub = ModelHub.from_github_repo()\n",
    "        self.modelhub.parse_objects()\n",
    "\n",
    "        self.data: Objects = Objects.from_modelhub(modelhub=self.modelhub)\n",
    "\n",
    "    @property\n",
    "    def asset(self):\n",
    "        if not self._asset:\n",
    "            self._asset = self.repo.get_release_asset(self._asset_id)\n",
    "        return self._asset\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_resnet_label(asset_name: str) -> str:\n",
    "        \"\"\"\n",
    "        asset_name: dog2312.onnx chess_piece2309.onnx\n",
    "        \"\"\"\n",
    "        onnx_archive = asset_name.replace(\".onnx\", \"\")\n",
    "        i_end = -1\n",
    "        for i, s in enumerate(onnx_archive):\n",
    "            if s.isdigit():\n",
    "                i_end = i\n",
    "                break\n",
    "        label = onnx_archive[:i_end]\n",
    "        label = label.replace(\"_\", \" \")\n",
    "        return label\n",
    "\n",
    "    def handle_resnet_objects(self):\n",
    "        onnx_archive = self.asset.name.replace(\".onnx\", \"\")\n",
    "        matched_label = self._matched_label or self.parse_resnet_label(self.asset.name)\n",
    "        old_onnx_archive = self.modelhub.label_alias.get(matched_label)\n",
    "\n",
    "        # Match: create new case\n",
    "        if not old_onnx_archive:\n",
    "            self.data.label_alias[onnx_archive] = {\"en\": [matched_label]}\n",
    "        # Match: update old case\n",
    "        else:\n",
    "            i18n_mapping = self.data.label_alias[old_onnx_archive].copy()\n",
    "            del self.data.label_alias[old_onnx_archive]\n",
    "            self.data.label_alias[onnx_archive] = i18n_mapping\n",
    "\n",
    "    def handle_nested_objects(self, model_pending: str):\n",
    "        \"\"\"\n",
    "        Match nested cases:\n",
    "        - the largest animal\n",
    "        - the smallest animal\n",
    "        \"\"\"\n",
    "        bond_nested_prompt = handle(self._matched_label)\n",
    "        if not bond_nested_prompt:\n",
    "            raise ValueError(\"Nested model requires binding prompt\")\n",
    "\n",
    "        # nested_largest_dog2309.onnx nested_largest_elephant2309.onnx\n",
    "        prefix_tag_pending = self.parse_resnet_label(model_pending)\n",
    "\n",
    "        # Match: 已注册的嵌套类型（bond_nested_prompt）\n",
    "        if nested_models := self.modelhub.nested_categories.get(bond_nested_prompt, []):\n",
    "            # prompt已注册但被错误赋值\n",
    "            if not isinstance(nested_models, list):\n",
    "                # 如果存在确切的值，则返回错误\n",
    "                if nested_models:\n",
    "                    raise TypeError(\n",
    "                        f\"NestedTypeError ({bond_nested_prompt}) 的模型映射列表应该是个 List[str] 类型，但实际上是 {type(nested_models)}\"\n",
    "                    )\n",
    "                # 如果prompt存在但未被赋有效值，则尝试恢复程序重建秩序\n",
    "                nested_models = []\n",
    "            # 查询 prompt 对应的模型匹配列表，更新「同项模型」的版本索引\n",
    "            idx_old_points: List[int] = []\n",
    "            for i, model_name in enumerate(nested_models):\n",
    "                prefix_tag_in_the_slot = self.parse_resnet_label(model_name)\n",
    "                if prefix_tag_in_the_slot == prefix_tag_pending:\n",
    "                    idx_old_points.append(i)\n",
    "            # 若 prompt 对应的模型匹配列表找不到「同项模型」更旧的版本，则直接插入新的模型\n",
    "            for i in idx_old_points:\n",
    "                nested_models.pop(i)\n",
    "            nested_models.append(model_pending)\n",
    "        # Match: 未注册的嵌套模型\n",
    "        else:\n",
    "            nested_models = [model_pending]\n",
    "\n",
    "        # 恢复嵌套模型的上下文，更新模型索引\n",
    "        self.data.nested_categories[bond_nested_prompt] = nested_models\n",
    "\n",
    "    def flush_remote_objects(self):\n",
    "        data_tmp_path = self.data.to_yaml()\n",
    "\n",
    "        res = self.data.to_asset(\n",
    "            self.repo,\n",
    "            message=f\"ci(annotator): update model `{self.asset.name}`\",\n",
    "            data_tmp_path=data_tmp_path,\n",
    "        )\n",
    "\n",
    "        logger.success(f\"upgrade objects\", response=res)\n",
    "\n",
    "        os.remove(data_tmp_path)\n",
    "\n",
    "    def execute(self):\n",
    "        logger.debug(f\"capture asset\", name=self.asset.name, url=self.asset.browser_download_url)\n",
    "\n",
    "        # Match: ResNet MoE models\n",
    "        if \"yolov8\" in self.asset.name:\n",
    "            return\n",
    "        if \"nested_\" in self.asset.name:\n",
    "            self.handle_nested_objects(self.asset.name)\n",
    "        else:\n",
    "            self.handle_resnet_objects()\n",
    "\n",
    "        self.flush_remote_objects()\n",
    "\n",
    "\n",
    "def rolling_upgrade(asset_id=None, matched_label: str = \"\"):\n",
    "    \"\"\"\n",
    "    When uploading a nested model, you need to specify the nesting type of the model binding.\n",
    "    \"\"\"\n",
    "    if not asset_id:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        annotator = Annotator(asset_id, matched_label=matched_label)\n",
    "        annotator.execute()\n",
    "    except Exception as err:\n",
    "        logger.warning(err)\n",
    "\n",
    "\n",
    "if not os.getenv(\"GITHUB_TOKEN\"):\n",
    "    logger.warning(\"Skip the rolling upgrade task, miss GITHUB TOKEN\")\n",
    "    sys.exit()\n",
    "\n",
    "rolling_upgrade(asset_id=aid, matched_label=NESTED_PROMPT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "energy conservation\n",
    "\"\"\"\n",
    "if IS_AUTODL_PLATFORM:\n",
    "    os.system(\"unset http_proxy && unset https_proxy\")\n",
    "    os.system(\"/usr/bin/shutdown\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
